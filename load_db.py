"""

This file retrieves stock information for all symbols generated by
the gen_symbols file. It will do an http request to gather information
then store it into the mongo database

Meant to be executed once a day (at market close)

"""

import urllib2
import re
from pymongo import MongoClient
from Symbol import Symbol
from threading import Thread
from Queue import Queue

NUMB_WORKERS = 50
FILES = ["Custom.csv"]
PREFIX = "data/"
BASE_URL = "http://finance.yahoo.com/q?s="

client = MongoClient('localhost', 27017)
db = client.stock_finder
stocks = db.stocks
sectors = db.sectors

# worker function for thread. Calls get_url
# then calls process_response
def worker():
    while True:
        obj = q.get()
        ticker = obj[0]
        name = obj[1]
        sect = obj[2]

        content = get_url(ticker)
        process_response(content, name, ticker, sect)

        q.task_done()

# Execute http request and return response
def get_url(symbol):
    return urllib2.urlopen(BASE_URL + symbol).read()

# This function processes an http request
# it will then upsert the information into the
# mongo datastore
def process_response(content, name, ticker, sect):
    try:
        symbol = Symbol(content, name, ticker)

        if symbol:
            print "Inserting ... " + ticker
            stocks.update({"_id": ticker}, symbol, upsert=True)
            sectors.update({"_id": sect}, {"$addToSet": {"symbols": ticker}}, upsert=True);

    except:
        return "error"


# Initialize thread pool
q = Queue(NUMB_WORKERS)
for i in range(NUMB_WORKERS):
    t = Thread(target=worker)
    t.daemon = True
    t.start()

# Read every file
for file_name in FILES:

    f = open(PREFIX + file_name, 'r')
    sector = re.match(r"(\w*)", file_name).group(1)

    # retrieve stock info for each symbol
    for line in f:

        tokens = line.split(";")

        if len(tokens) == 2:
            q.put((tokens[0], tokens[1], sector))


q.join()

