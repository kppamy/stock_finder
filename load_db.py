"""

This file retrieves stock information for all symbols generated by
the gen_symbols file. It will do an http request to gather information
then store it into the mongo database

Meant to be executed once a day (at market close)

"""
import sqlite3
import urllib2
import re
import time

from Symbol import Symbol
from threading import Thread
from Queue import Queue

import queries

NUMB_WORKERS = 50
FILES = [ "Favourites.csv"]
PREFIX = "data/"
BASE_URL = "http://finance.yahoo.com/q?s="

#create the database
queries.create_db()

symbol_queue = Queue()


# worker function for thread. Calls get_url
# then calls process_response
def fetch_symbol():
    while True:
        obj = q.get()
        ticker = obj[0]
        name = obj[1]
        sect = obj[2]

        content = urllib2.urlopen(BASE_URL + ticker).read()
        symbol = Symbol(content, name, ticker)

        if symbol:
            symbol_queue.put((symbol, sect))

        q.task_done()


def add_symbol():
    db = sqlite3.connect('db/stock_finder')
    count = 0
    while True:

        while symbol_queue.qsize() > 0:
            obj = symbol_queue.get()
            queries.insert_row(obj[0], obj[1], db)
            count = 0

        if count == 10:
            break;
        else:
            time.sleep(1)
            print "Queue empty sleeping ..."
            count += 1;

    db.close()

# Initialize thread pool
q = Queue(NUMB_WORKERS)
for i in range(NUMB_WORKERS):
    t = Thread(target=fetch_symbol)
    t.daemon = True
    t.start()


w = Thread(target=add_symbol)
w.start();

# Read every file
for file_name in FILES:

    f = open(PREFIX + file_name, 'r')
    sector = re.match(r"(\w*)", file_name).group(1)

    # Add sector record
    queries.insert_sectors(sector)

    # retrieve stock info for each symbol
    for line in f:

        tokens = line.split(";")

        if len(tokens) == 2:
            q.put((tokens[0], tokens[1], sector))


q.join()

